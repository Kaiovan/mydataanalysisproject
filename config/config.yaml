# Configuration file for Clickstream Analytics Pipeline

# Data Generation Settings
data_generation:
  num_users: 1000
  num_products: 500
  num_sessions: 10000
  days_range: 30
  output_format: csv  # csv, json, jsonl

# Spark Settings
spark:
  app_name: "E-commerce Clickstream ETL"
  driver_memory: "4g"
  executor_memory: "4g"
  executor_cores: 2
  adaptive_enabled: true
  shuffle_partitions: 200
  log_level: "WARN"

# Database Settings
database:
  type: postgresql
  host: localhost
  port: 5432
  database: clickstream_warehouse
  username: dataeng
  password: dataeng123
  schema: public

# Pipeline Settings
pipeline:
  input_path: "data/raw/clickstream_events.csv"
  output_path: "data/processed"
  checkpoint_path: "data/checkpoints"
  partition_columns:
    - event_date
  compression: snappy

# Analytics Settings
analytics:
  output_path: "data/analytics_output"
  chart_style: whitegrid
  dpi: 300

# Performance Tuning
performance:
  cache_intermediate_results: true
  broadcast_threshold: 10485760  # 10MB
  auto_broadcast_join_threshold: 10485760

# ML Settings
ml:
  enabled: true
  output_path: "data/ml_output"
  random_state: 42
  test_size: 0.2
  cv_folds: 5
  models:
    conversion:
      algorithm: RandomForest
      n_estimators: 100
      max_depth: 10
    churn:
      algorithm: RandomForest
      churn_threshold_days: 7
      n_estimators: 100
      max_depth: 10
    ltv:
      algorithm: GradientBoosting
      n_estimators: 100
      max_depth: 5
      learning_rate: 0.1

# AI / Natural Language Query Settings
ai:
  model: "claude-sonnet-4-20250514"
  max_tokens: 1024
  temperature: 0.0
  max_result_rows: 100
  query_timeout_seconds: 30

# Logging
logging:
  level: INFO
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/pipeline.log"
